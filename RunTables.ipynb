{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sql_queries import create_table_queries, drop_table_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_database():\n",
    "    \"\"\"\n",
    "    - Creates and connects to the sparkifydb\n",
    "    - Returns the connection and cursor to sparkifydb\n",
    "    \"\"\"\n",
    "    \n",
    "    # connect to default database\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=studentdb user=student password=student\")\n",
    "    conn.set_session(autocommit=True)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    #var= cur.execute('select * from pg_stat_activity;')\n",
    "    \n",
    "    # create sparkify database with UTF8 encoding\n",
    "    #cur.execute('REVOKE CONNECT ON DATABASE sparkifydb FROM public;')\n",
    "    #cur.execute('SELECT pg_terminate_backend(pg_stat_activity.pid) FROM pg_stat_activity WHERE pg_stat_activity.datname = 'sparkifydbs' AND pid <> pg_backend_pid();')\n",
    "    cur.execute(\"DROP DATABASE IF EXISTS sparkifydb\")\n",
    "    cur.execute(\"CREATE DATABASE sparkifydb WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "    cur.execute('GRANT CONNECT ON DATABASE sparkifydb TO public;')\n",
    "\n",
    "    # close connection to default database\n",
    "    conn.close()    \n",
    "    \n",
    "    # connect to sparkify database\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "    cur = conn.cursor()\n",
    "    conn.set_session(autocommit=True)\n",
    "    \n",
    "    return cur, conn\n",
    "\n",
    "\n",
    "def drop_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Drops each table using the queries in `drop_table_queries` list.\n",
    "    \"\"\"\n",
    "    \n",
    "    #drops tables if there are any defined on the variable drop list\n",
    "    \n",
    "    for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "        \n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Creates each table using the queries in `create_table_queries` list. \n",
    "    \"\"\"\n",
    "    #creates tables defined on the create table queries list variable, iterates and commit creation of table on by one\n",
    "    \n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    - Drops (if exists) and Creates the sparkify database. \n",
    "    \n",
    "    - Establishes connection with the sparkify database and gets\n",
    "    cursor to it.  \n",
    "    \n",
    "    - Drops all the tables.  \n",
    "    \n",
    "    - Creates all tables needed. \n",
    "    \n",
    "    - Finally, closes the connection. \n",
    "    \"\"\"\n",
    "    \n",
    "    #cur and conn will be equal to what is returned by the create_database function\n",
    "    cur, conn = create_database()\n",
    "    \n",
    "    drop_tables(cur, conn)\n",
    "    create_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Sparkify Startup**\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "A startup called **Sparkify** wants to **analyze the data** they've been collecting *on songs and user activity on their new music streaming app*. The analytics team is particularly interested in understanding **what songs users are listening to**. Currently, they don't have an easy way to query their data, which resides in a directory of *JSON logs* on user activity on the app, as well as a directory with JSON metadata on the songs in their app.\n",
    "\n",
    "As a **data engineer** I need to create a *Postgres database* with **tables designed to optimize queries on song play analysis** for this project. My role is to create a **database schema and ETL pipeline for this analysis**. I'll be able to test the database and ETL pipeline by *running queries given to me by the analytics team* from Sparkify and *compare my results with their expected results*.\n",
    "\n",
    "**Project Description**\n",
    "\n",
    "In this project, I'll apply data modeling with Postgres and build an ETL pipeline using Python. To complete the project, I will *define fact and dimension tables* for a **star schema** for a particular *analytic focus*, and write an **ETL pipeline that transfers data from files in two local directories into these tables in Postgres using Python and SQL.\n",
    "\n",
    "\n",
    "**Objective 1:** \n",
    "\n",
    ">Designed a Database with five table, *Songplays_table, users_table, songs_table, artist_table and time_table*. The purpose of this Database is to store all tables records, tracking users interaction with songs in database, which song was most played and by which artist. And be able to select all the songs played by song and artist from a subset of a much larger dataset.\n",
    "\n",
    "***Sparkify Postgres Database Design***\n",
    "\n",
    "`Table Name: Songplays_table\n",
    "column: songplay_id\n",
    "column: start_time\n",
    "column: user_id\n",
    "column: level\n",
    "column: song_id\n",
    "column: artist_id\n",
    "column: session_id\n",
    "column: location\n",
    "column: user_agent`\n",
    "\n",
    "`Table Name: users_table\n",
    "column: user_id\n",
    "column: first_name\n",
    "column: last_name\n",
    "column: gender\n",
    "column: level`\n",
    "\n",
    "`Table Name: songs_table\n",
    "column: song_id\n",
    "column: title\n",
    "column: artist_id\n",
    "column: year\n",
    "column: duration`\n",
    "\n",
    "`Table Name: artist_table\n",
    "column: artist_id\n",
    "column: name\n",
    "column: location\n",
    "column: latitude\n",
    "column: longitude`\n",
    "\n",
    "`Table Name: time_table\n",
    "column: start_time\n",
    "column: hour\n",
    "column: day\n",
    "column: week\n",
    "column: month\n",
    "column: year\n",
    "column: weekday`\n",
    "\n",
    "<img src=\"data/Image/SparkifyStar.PNG\" width=\"750\" height=\"750\">\n",
    "             \n",
    "**Implement etl.py:** \n",
    "\n",
    "1. On Jupyter Notebook\n",
    "2. Create a Cell\n",
    "3. Write this code : `%run etl.py`\n",
    "4. Run cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
